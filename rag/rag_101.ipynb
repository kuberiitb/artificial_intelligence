{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsBsnH/N7UJOFxYqlPyDda",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuberiitb/artificial_intelligence/blob/main/rag/rag_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBZfob2hjLrZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain_openai langchain-community pypdf chromadb opentelemetry-api opentelemetry-sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import chromadb\n",
        "\n",
        "from pprint import pprint\n",
        "from IPython.display import Markdown, Image, display, HTML"
      ],
      "metadata": {
        "id": "SPQROBd3jgG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "try:\n",
        "  os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except:\n",
        "  print(\"Set OPENAI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "PtD41P03jzPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zH8wiP8otme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOC_PATH = \"/content/Building Effective AI Agents.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(DOC_PATH)\n",
        "pages = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "UatCO5o7kNlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHROMA_PATH = \"/content/chroma_path\"\n",
        "os.makedirs(CHROMA_PATH,exist_ok=True)\n",
        "db_chroma = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)"
      ],
      "metadata": {
        "id": "XW5kML1zl8Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What is AI Agent?'\n",
        "\n",
        "query = 'What do frameworks do?'\n",
        "\n",
        "docs_chroma = db_chroma.similarity_search_with_score(query, k=5)\n",
        "\n",
        "context_text = \"\\n\\n\".join([doc.page_content for doc, _score in docs_chroma])"
      ],
      "metadata": {
        "id": "qeqLDpo6m1Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFEw8xuRn3Oq",
        "outputId": "bb8e21ca-34b1-4a47-aaee-d3e889c76c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "be implemented in a few lines of code. If you do use a framework, ensure you\n",
            "understand the underlying code. Incorrect assumptions about what's under the\n",
            "hood are a common source of customer error.\n",
            "Skip to main contentSkip to footer\n",
            "\n",
            "These frameworks make it easy to get started by simplifying standard low-level\n",
            "tasks like calling LLMs, defining and parsing tools, and chaining calls together.\n",
            "However, they often create extra layers of abstraction that can obscure the\n",
            "underlying prompts   and responses, making them harder to debug. They can also\n",
            "make it tempting to add complexity when a simpler setup would suffice.\n",
            "We suggest that developers start by using LLM APIs directly: many patterns can\n",
            "\n",
            "flexibility and model-driven decision-making are needed at scale. For many\n",
            "applications, however, optimizing single LLM calls with retrieval and in-context\n",
            "examples is usually enough.\n",
            "When and how to use frameworks\n",
            "There are many frameworks that make agentic systems easier to implement,\n",
            "including:\n",
            "LangGraph from LangChain;\n",
            "Amazon Bedrock's AI Agent framework;\n",
            "Rivet, a drag and drop GUI LLM workflow builder; and\n",
            "Vellum, another GUI tool for building and testing complex workflows.\n",
            "\n",
            "documentation and testing.\n",
            "Frameworks can help you get started quickly, but don't hesitate to reduce\n",
            "abstraction layers and build with basic components as you move to production.\n",
            "By following these principles, you can create agents that are not only powerful\n",
            "but also reliable, maintainable, and trusted by their users.\n",
            "Acknowledgements\n",
            "Written by Erik Schluntz and Barry Zhang. This work draws upon our\n",
            "experiences building agents at Anthropic and the valuable insights shared by our\n",
            "\n",
            "patterns rather than complex frameworks.\n",
            "Published Dec 19, 2024\n",
            "Over the past year, we've worked with dozens of teams building large language\n",
            "model (LLM) agents across industries. Consistently, the most successful\n",
            "implementations weren't using complex frameworks or specialized libraries.\n",
            "Instead, they were building with simple, composable patterns.\n",
            "In this post, we share what we’ve learned from working with our customers and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "{context}\n",
        "\\n\\n\n",
        "Answer the question based on the above context: {question}.\n",
        "Provide a detailed answer.\n",
        "Don’t justify your answers.\n",
        "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
        "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "prompt = prompt_template.format(context=context_text, question=query)"
      ],
      "metadata": {
        "id": "I_SYs00en4Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzlwzSvzoSRD",
        "outputId": "d97c97bb-c7e1-4bc1-837e-a18d0a5f1c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: \n",
            "Answer the question based only on the following context:\n",
            "be implemented in a few lines of code. If you do use a framework, ensure you\n",
            "understand the underlying code. Incorrect assumptions about what's under the\n",
            "hood are a common source of customer error.\n",
            "Skip to main contentSkip to footer\n",
            "\n",
            "These frameworks make it easy to get started by simplifying standard low-level\n",
            "tasks like calling LLMs, defining and parsing tools, and chaining calls together.\n",
            "However, they often create extra layers of abstraction that can obscure the\n",
            "underlying prompts   and responses, making them harder to debug. They can also\n",
            "make it tempting to add complexity when a simpler setup would suffice.\n",
            "We suggest that developers start by using LLM APIs directly: many patterns can\n",
            "\n",
            "flexibility and model-driven decision-making are needed at scale. For many\n",
            "applications, however, optimizing single LLM calls with retrieval and in-context\n",
            "examples is usually enough.\n",
            "When and how to use frameworks\n",
            "There are many frameworks that make agentic systems easier to implement,\n",
            "including:\n",
            "LangGraph from LangChain;\n",
            "Amazon Bedrock's AI Agent framework;\n",
            "Rivet, a drag and drop GUI LLM workflow builder; and\n",
            "Vellum, another GUI tool for building and testing complex workflows.\n",
            "\n",
            "documentation and testing.\n",
            "Frameworks can help you get started quickly, but don't hesitate to reduce\n",
            "abstraction layers and build with basic components as you move to production.\n",
            "By following these principles, you can create agents that are not only powerful\n",
            "but also reliable, maintainable, and trusted by their users.\n",
            "Acknowledgements\n",
            "Written by Erik Schluntz and Barry Zhang. This work draws upon our\n",
            "experiences building agents at Anthropic and the valuable insights shared by our\n",
            "\n",
            "patterns rather than complex frameworks.\n",
            "Published Dec 19, 2024\n",
            "Over the past year, we've worked with dozens of teams building large language\n",
            "model (LLM) agents across industries. Consistently, the most successful\n",
            "implementations weren't using complex frameworks or specialized libraries.\n",
            "Instead, they were building with simple, composable patterns.\n",
            "In this post, we share what we’ve learned from working with our customers and\n",
            "\n",
            "\n",
            "\n",
            "Answer the question based on the above context: What do frameworks do?.\n",
            "Provide a detailed answer.\n",
            "Don’t justify your answers.\n",
            "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
            "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
        "                    temperature=0.2,\n",
        "                    max_tokens=100)\n",
        "\n",
        "response_text = llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "jCJCpiNToXMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(response_text.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "1CyWNpCEoo9g",
        "outputId": "9a16a428-d909-4036-d478-c5fcfb1813d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Frameworks simplify standard low-level tasks such as calling large language models (LLMs), defining and parsing tools, and chaining calls together. They make it easier to get started with implementing agentic systems. However, they often introduce extra layers of abstraction that can obscure the underlying prompts and responses, making debugging more challenging. Frameworks can also tempt developers to add unnecessary complexity when a simpler setup would suffice. While they help in getting started quickly, it is suggested to reduce abstraction layers and build with basic components'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SwuKVtDUpW-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocAnswers:\n",
        "  def __init__(self, model_name=\"gpt-4o-mini\",\n",
        "               DOC_PATH=\"/content/Building Effective AI Agents.pdf\",\n",
        "               ):\n",
        "    self.llm = ChatOpenAI(model=model_name,\n",
        "                    temperature=0.2,\n",
        "                    max_tokens=10000)\n",
        "\n",
        "    self.response_text = llm.invoke(prompt)\n",
        "    self.DOC_PATH = DOC_PATH\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"\n",
        "    Answer the question based only on the following context:\n",
        "    {context}\n",
        "    \\n\\n\n",
        "    Answer the question based on the above context: {question}.\n",
        "    If you can not find the answer in the context, reply \"Sorry, I don't know that.\"\n",
        "    Provide a short answer in 50-100 words.\n",
        "    Don’t justify your answers.\n",
        "    Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
        "    Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
        "    \"\"\"\n",
        "\n",
        "    self.prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "  def update_db(self):\n",
        "\n",
        "    loader = PyPDFLoader(self.DOC_PATH)\n",
        "    pages = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    chunks = text_splitter.split_documents(pages)\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "    self.docs_chroma = db_chroma.similarity_search_with_score(query, k=5)\n",
        "\n",
        "  def get_answer(self, query):\n",
        "    context_text = \"\\n\\n\".join([doc.page_content for doc, _score in self.docs_chroma])\n",
        "    self.prompt = prompt_template.format(context=context_text, question=query)\n",
        "\n",
        "    self.response_text = llm.invoke(self.prompt)\n",
        "    # print(self.response_text)\n",
        "    return display(Markdown(self.response_text.content))\n"
      ],
      "metadata": {
        "id": "LSfOrGgSqQd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = DocAnswers()"
      ],
      "metadata": {
        "id": "itfizsoGsDLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers.update_db()"
      ],
      "metadata": {
        "id": "2nkUG5gBsFED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What's the difference between a workflow and an agent?\"\n",
        "\n",
        "answers.get_answer(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "hsC1-n1tuciJ",
        "outputId": "d5c44119-cf12-4bcc-a94a-c3c892bb97f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A workflow is a system where LLMs and tools are orchestrated through predefined code paths. It provides predictability and consistency for well-defined tasks, allowing for the separation of concerns and the building of more specialized prompts. Workflows are particularly effective for complex tasks with distinct categories that are better handled separately.\n\nAn agent, on the other hand, is a system where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks. Agents begin their work with a command"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What's the difference between a workflow and an agent in one line?\"\n",
        "\n",
        "answers.get_answer(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "IR4taCaasHWK",
        "outputId": "295aec8c-5c93-4c44-a6ab-3917bf25fe31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A workflow is a system where LLMs and tools follow predefined code paths for task execution, while an agent is a system where LLMs dynamically direct their own processes and tool usage to accomplish tasks."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers.get_answer(\"What is India's capital city?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "oVF6CRv5sZab",
        "outputId": "04f4e6e8-95a2-4854-e19b-35c52d10a661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The provided context does not contain any information regarding India's capital city. Therefore, I cannot provide an answer to that question."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers.get_answer(\"What is an AI Agent, tell in 2 short bullet points?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "vya8doyXvWNe",
        "outputId": "01fd84fe-8e6c-4745-a6ec-623cee29b8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- An AI Agent is a system where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.\n- Agents begin their work with a command or interactive discussion with the human user, planning and operating independently while potentially returning for further information or judgment."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What's the difference between a workflow and an agent?\",\n",
        "    \"What's the main idea behind the 'augmented LLM'?\",\n",
        "    \"What is the 'prompt chaining' workflow and when should it be used?\",\n",
        "    \"What is the purpose of the 'routing' workflow?\",\n",
        "    \"What are the two main variations of the 'parallelization' workflow?\",\n",
        "    \"How is the 'orchestrator-workers' workflow different from parallelization?\",\n",
        "    \"What is the 'evaluator-optimizer' workflow and when is it effective?\",\n",
        "    \"When should developers consider using a framework for building agentic systems?\",\n",
        "    \"What are the main characteristics of an autonomous agent?\",\n",
        "    \"What are the three core principles for implementing effective agents?\"\n",
        "]"
      ],
      "metadata": {
        "id": "l9_P2lwOtRAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question in questions:\n",
        "  print(question)\n",
        "  answers.get_answer(question)\n",
        "  print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QmjC39OPt1qP",
        "outputId": "d54e6381-9956-4431-fd06-17bb40bd7a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What's the difference between a workflow and an agent?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A workflow is a system where LLMs and tools are orchestrated through predefined code paths. It provides predictability and consistency for well-defined tasks, allowing for the separation of concerns and the building of more specialized prompts. Workflows are suitable for complex tasks with distinct categories that are better handled separately.\n\nAn agent, on the other hand, is a system where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks. Agents begin their work with a command from"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "What's the main idea behind the 'augmented LLM'?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The main idea behind the 'augmented LLM' is to enhance the capabilities of large language models (LLMs) by integrating them with tools and systems that allow for more dynamic and interactive processes. This involves two types of agentic systems: workflows and agents. \n\nWorkflows are characterized by predefined code paths that orchestrate the LLMs and tools, providing predictability and consistency for well-defined tasks. They are particularly useful for complex tasks that require distinct categorization and specialized handling.\n\nOn the"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "What is the 'prompt chaining' workflow and when should it be used?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The 'prompt chaining' workflow is not explicitly defined in the provided context. Therefore, there is no information available regarding what prompt chaining is or when it should be used."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "What is the purpose of the 'routing' workflow?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The purpose of the 'routing' workflow is to classify an input and direct it to a specialized follow-up task. This workflow allows for the separation of concerns and the building of more specialized prompts. It is particularly effective for complex tasks where there are distinct categories that are better handled separately. Without this workflow, optimizing for one kind of input can negatively impact performance on other inputs."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "What are the two main variations of the 'parallelization' workflow?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The two main variations of the 'parallelization' workflow are:\n\n1. **Task Parallelization**: This variation involves breaking down a complex task into smaller, independent subtasks that can be executed simultaneously. This allows for more efficient processing and can significantly reduce the overall time required to complete the task.\n\n2. **Data Parallelization**: This variation focuses on distributing a large dataset across multiple processing units or agents. Each unit processes a portion of the data in parallel, which enhances performance and speeds up"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "How is the 'orchestrator-workers' workflow different from parallelization?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The 'orchestrator-workers' workflow involves a structured approach where an orchestrator directs multiple workers to perform specific tasks in a coordinated manner. This workflow is characterized by predefined paths and a clear hierarchy of task management, ensuring that each worker has a defined role and responsibility within the overall process.\n\nIn contrast, parallelization refers to the simultaneous execution of multiple tasks or processes without a central orchestrator managing their interactions. In parallelization, tasks can operate independently and may not require coordination or predefined paths, allowing"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "What is the 'evaluator-optimizer' workflow and when is it effective?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The 'evaluator-optimizer' workflow is not explicitly defined in the provided context. Therefore, there is no information available regarding its effectiveness or specific characteristics."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "When should developers consider using a framework for building agentic systems?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Developers should consider using a framework for building agentic systems when more complexity is warranted in their applications with LLMs. This is particularly relevant when the tasks require dynamic direction and control over processes and tool usage. Agentic systems are beneficial when handling complex inputs, engaging in reasoning and planning, and utilizing tools reliably. They are also suitable for scenarios where the system needs to recover from errors and maintain an interactive discussion with the human user to clarify tasks.\n\nAdditionally, developers should consider agentic systems when"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "What are the main characteristics of an autonomous agent?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "An autonomous agent is characterized by the following main features:\n\n1. **Dynamic Direction**: Agents have the ability to dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.\n\n2. **Initiation**: They begin their work with either a command from or an interactive discussion with the human user to clarify the task.\n\n3. **Independent Operation**: Once the task is clear, agents can plan and operate independently without constant human intervention.\n\n4. **Interaction and Adaptability"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "What are the three core principles for implementing effective agents?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The three core principles for implementing effective agents are:\n\n1. **Dynamic Direction**: Agents should be capable of dynamically directing their own processes and tool usage, allowing them to maintain control over how they accomplish tasks.\n\n2. **Interactive Engagement**: Agents begin their work with either a command from or interactive discussion with the human user, ensuring that the task is clear before they plan and operate independently.\n\n3. **Tool Integration**: Agents should integrate tools effectively to enhance their capabilities, allowing them to access"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we used recursive chunking RecursiveCharacterTextSplitter.\n",
        "\n",
        "## Issues in the output:\n",
        "- Output is not complete\n",
        "- In one case, model did not retrieve anything at all, so we need to check the issue with Retriever."
      ],
      "metadata": {
        "id": "ZAhTIR7WyDBR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BV0aW3NLwZA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}